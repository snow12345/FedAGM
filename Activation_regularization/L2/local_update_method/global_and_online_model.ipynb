{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        # 여기에 모든 모듈을 생성해두고,\n",
    "        # 나중에 여기에서 선언해둔 이름으로 사용할 수 있습니다.\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(1, 5)\n",
    "        self.fc2 = nn.Linear(5, 1)\n",
    "\n",
    "    # 순전파 함수에서는 신경망의 구조를 정의합니다.\n",
    "    # 여기에서는 단 하나의 입력만 받지만, 필요하면 더 받도록 변경하면 됩니다.\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=SaveOutput()\n",
    "for layer in net.modules():\n",
    "    handle = layer.register_forward_hook(s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.SaveOutput object at 0x7f917a6374d0>\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([[1.0]])\n",
    "y=net(x)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 1.7720,  1.3475, -0.2756, -1.2219, -0.9436]],\n",
      "       grad_fn=<AddmmBackward>), tensor([[0.3639]], grad_fn=<AddmmBackward>), tensor([[0.3639]], grad_fn=<ReluBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "print(s.get_outputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for a in s.get_outputs():\n",
    "    print(a.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pod(\n",
    "    list_attentions_a,\n",
    "    list_attentions_b,\n",
    "    collapse_channels=\"spatial\",\n",
    "    normalize=True,):\n",
    "    loss = torch.tensor(0.).to(list_attentions_a[0].device)\n",
    "    for i, (a, b) in enumerate(zip(list_attentions_a, list_attentions_b)):\n",
    "        a = torch.pow(a, 2)\n",
    "        b = torch.pow(b, 2)\n",
    "        if collapse_channels == \"channels\":\n",
    "            a = a.sum(dim=1).view(a.shape[0], -1)  # shape of (b, w * h)\n",
    "            b = b.sum(dim=1).view(b.shape[0], -1)\n",
    "        elif collapse_channels == \"width\":\n",
    "            a = a.sum(dim=2).view(a.shape[0], -1)  # shape of (b, c * h)\n",
    "            b = b.sum(dim=2).view(b.shape[0], -1)\n",
    "        elif collapse_channels == \"height\":\n",
    "            a = a.sum(dim=3).view(a.shape[0], -1)  # shape of (b, c * w)\n",
    "            b = b.sum(dim=3).view(b.shape[0], -1)\n",
    "        elif collapse_channels == \"gap\":\n",
    "            a = F.adaptive_avg_pool2d(a, (1, 1))[..., 0, 0]\n",
    "            b = F.adaptive_avg_pool2d(b, (1, 1))[..., 0, 0]\n",
    "        elif collapse_channels == \"spatial\":\n",
    "            a_h = a.sum(dim=3).view(a.shape[0], -1)\n",
    "            b_h = b.sum(dim=3).view(b.shape[0], -1)\n",
    "            a_w = a.sum(dim=2).view(a.shape[0], -1)\n",
    "            b_w = b.sum(dim=2).view(b.shape[0], -1)\n",
    "            a = torch.cat([a_h, a_w], dim=-1)\n",
    "            b = torch.cat([b_h, b_w], dim=-1)\n",
    "        elif collapse_channels == \"pixel\":\n",
    "            pass        \n",
    "        else:\n",
    "            raise ValueError(\"Unknown method to collapse: {}\".format(collapse_channels))\n",
    "\n",
    "        if normalize:\n",
    "            a = F.normalize(a, dim=1, p=2)\n",
    "            b = F.normalize(b, dim=1, p=2)\n",
    "\n",
    "        layer_loss = torch.mean(torch.frobenius_norm(a - b, dim=-1))\n",
    "        loss += layer_loss\n",
    "    return loss / len(list_attentions_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "        \n",
    "    def __call__(self, module, module_in, module_out):\n",
    "        self.outputs.append(module_out)\n",
    "        \n",
    "    def clear(self):\n",
    "        self.outputs = []\n",
    "    \n",
    "    def get_outputs(self):\n",
    "        return self.outputs\n",
    "    \n",
    "\n",
    "\n",
    "def freeze_parameters(model):\n",
    "    for n,m in model.named_parameters():\n",
    "        param.grad=None\n",
    "        m.requires_grad=False\n",
    "\n",
    "class global_and_online_model(nn.Module):\n",
    "    def __init__(self,args,online_model,global_model):\n",
    "        super(global_and_online_mode,self).__init__()\n",
    "        self.args=args\n",
    "        self.online_model=online_model\n",
    "        self.global_model=copy.deepcopy(global_model)\n",
    "        freeze_parameters(self.global_model)\n",
    "\n",
    "        \n",
    "        self.online_save_output = SaveOutput()\n",
    "        self.global_save_output = SaveOutput()\n",
    "    \n",
    "\n",
    "        #현재 구현 상태: 각 Conv layer의 ouptut을 가지고 와서 그들의 distillation loss를 pod function을 이용해 구함\n",
    "        #추후에 Resnet stage 단위로 바꿀 수 있다(Podnet paper:https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123650086.pdf)\n",
    "        online_hook_handles=[]\n",
    "        for layer in self.online_model.modules():\n",
    "            layer_name=layer._get_name()\n",
    "            if self.args.regularization_unit in layer_name:\n",
    "                handle = layer.register_forward_hook(self.online_save_output)\n",
    "                online_hook_handles.append(handle)\n",
    "        \n",
    "        global_hook_handles=[]\n",
    "        for layer in self.global_model.modules():\n",
    "            layer_name=layer._get_name()\n",
    "            if self.args.regularization_unit in layer_name:\n",
    "                handle = layer.register_forward_hook(self.online_save_output)\n",
    "                online_hook_handles.append(handle)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    def forward(self, x,online_target=False):\n",
    "        if online_target==False:\n",
    "            return self.online_model(x)\n",
    "        \n",
    "        else:\n",
    "            self.online_save_output.clear()\n",
    "            self.global_save_output.clear()\n",
    "            \n",
    "            \n",
    "            x=self.online_model(x)\n",
    "            online_outputs=self.online_save_output.outputs[:-1]\n",
    "            \n",
    "            \n",
    "            x1=copy.deepcopy(x)\n",
    "            global_outputst=self.global_save_output.outputs[:-1]\n",
    "            \n",
    "            activation_loss=pod(    list_attentions_a=online_outputs,\n",
    "                    list_attentions_b=global_outputs,\n",
    "                    collapse_channels=self.args.collapse_channels,\n",
    "                    normalize=self.args.pod_normalize,)\n",
    "            \n",
    "            return x,activation_loss\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
